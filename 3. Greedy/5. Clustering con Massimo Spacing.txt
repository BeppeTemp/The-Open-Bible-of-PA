-------------------------------------------------------------------- Definizione del problema

Problema: 
    - Dividere i punti in cluster (gruppi) in modo che punti distinti si trovino in 
      cluster differenti

Input: 
    - insieme U di n oggetti e un intero K.

Obiettivo: 
    - Trovare un k-clustering con massimo spacing.

-------------------------------------------------------------------- Definizioni

Clustering: 
    - Dato un insieme U di n oggetti p1, ..., pn, vogliamo classificarli in gruppi coerenti.

Funzione distanza: 
    - Associa ad ogni coppia di oggetti un valore numerico che indica la vicinanza dei due oggetti.

k-clustering: 
    - Partizione dell'insieme U in k sottoinsiemi non vuoti (cluster)

Spacing: 
    - Distanza più piccola tra due oggeti in cluster differenti.

Funzione distanza: è una funzione che soddisfa le seguenti proprietà:
  * d(pi,pj)=0 se e solo se pi=pj
  * d(pi,pj)>=0
  * d(pi,pj)=d(pj,pi)
  
-------------------------------------------------------------------- Algoritmo basato sul single-link k-clustering

Funzionamento:
  * Costruire un grafo sull'insieme di vertici dell'insime U in modo che alla fine abbia K-componenti connesse.
    Ogni componente connessa corisponderà ad un cluster.
  * Inzialmente il grafo non contiene archi.
  * Ad ogni passo trova i due oggetti x e y più vicin e t.c. x e y siano in cluster distinti.
  * Aggiunge un arco tra x e y
    Va avanti fino a che ha ragiunto n-k archi: a quel punto ci sono esattamente k cluster.

Questa procedura corrisponde ad esguire l'algorimo di Kruskal su un grafo completo in cui i costi degli
archi rappresentano la distanza tra due oggetti: c(u, v) = d(u, v). L'unica differenza è che l'algoritmo si ferma prima di
inserire i k-1 archi più costosi dello MST.
-------------------------------------------------------------------- FIN
